# GPU Support in dsHPC

This document explains how GPU support works in dsHPC, including the adaptive auto-configuration system that detects and configures GPUs automatically.

## Quick Summary

dsHPC includes **automatic GPU detection and configuration**. When you run `./configure-environment.sh`:

1. **Detects** your GPU type (NVIDIA, AMD, or none)
2. **Validates** Docker GPU passthrough is working
3. **Configures** docker-compose.yml with GPU runtime
4. **Builds** the container with appropriate GPU libraries
5. **Sets up** Slurm GRES for GPU job scheduling

**No manual configuration required** - if your system has a working GPU setup, dsHPC will use it automatically.

## Platform Support Matrix

| Platform | GPU Type | Support Level | Notes |
|----------|----------|---------------|-------|
| Linux | NVIDIA | **Full** | Requires nvidia-container-toolkit |
| Linux | AMD | **Full** | Requires ROCm kernel driver |
| Windows WSL2 | NVIDIA | **Full** | Requires Windows NVIDIA driver |
| Windows WSL2 | AMD | None | Not supported by AMD |
| macOS Intel | Any | None | Docker Desktop limitation |
| macOS Apple Silicon | M1/M2/M3/M4 | None | Metal incompatible with CUDA/ROCm |

## How It Works

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              HOST SYSTEM                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚   GPU Driver     â”‚  NVIDIA Driver or AMD ROCm kernel module              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚ Container Toolkitâ”‚  nvidia-container-toolkit or amd-container-toolkit    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     DOCKER CONTAINER (dsHPC-slurm)                   â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ CUDA/ROCm Libs  â”‚  â”‚  Slurm + GRES   â”‚  â”‚    User Jobs         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ (in container)  â”‚  â”‚  (auto-config)  â”‚  â”‚  --gres=gpu:1        â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Configuration auto-generated by start-services.sh:                  â”‚   â”‚
â”‚  â”‚  - /etc/slurm/slurm.conf (with GresTypes=gpu)                       â”‚   â”‚
â”‚  â”‚  - /etc/slurm/gres.conf (with AutoDetect=nvml or rsmi)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detection Flow

```
configure-environment.sh
         â”‚
         â”œâ”€â–º detect_gpu_comprehensive()
         â”‚   â”œâ”€â–º Check OS (macOS â†’ no GPU support)
         â”‚   â”œâ”€â–º Check nvidia-smi â†’ NVIDIA GPU
         â”‚   â”œâ”€â–º Check /dev/kfd + rocm-smi â†’ AMD GPU
         â”‚   â””â”€â–º Check /dev/dri â†’ AMD fallback
         â”‚
         â”œâ”€â–º test_docker_gpu_nvidia() or test_docker_gpu_amd()
         â”‚   â””â”€â–º Validates Docker can actually access GPU
         â”‚
         â”œâ”€â–º configure_slurm()
         â”‚   â”œâ”€â–º Creates config/slurm.conf with GRES
         â”‚   â””â”€â–º Creates config/gres.conf
         â”‚
         â”œâ”€â–º configure_docker_compose_gpu()
         â”‚   â””â”€â–º Adds GPU runtime to docker-compose.yml
         â”‚
         â””â”€â–º build_images()
             â””â”€â–º Passes --build-arg GPU_TYPE=nvidia|amd|none
```

### Runtime Detection

Even after setup, the container performs runtime GPU detection on every startup:

```
start-services.sh (inside container)
         â”‚
         â”œâ”€â–º Detect actual GPUs visible to container
         â”‚   â”œâ”€â–º nvidia-smi for NVIDIA
         â”‚   â””â”€â–º rocm-smi or /dev/dri for AMD
         â”‚
         â”œâ”€â–º Validate matches build-time configuration
         â”‚
         â”œâ”€â–º Generate /etc/slurm/slurm.conf
         â”‚   â””â”€â–º With actual GPU count and type
         â”‚
         â””â”€â–º Generate /etc/slurm/gres.conf
             â””â”€â–º With AutoDetect or manual device mapping
```

This ensures the container works correctly even if:
- Moved between systems with different GPU counts
- GPU hardware changes
- Docker GPU configuration changes

## Prerequisites by Platform

### Linux with NVIDIA GPU

1. **Install NVIDIA Driver** (version 470+):
   ```bash
   # Ubuntu/Debian
   sudo apt-get update
   sudo apt-get install -y nvidia-driver-535

   # Verify
   nvidia-smi
   ```

2. **Install NVIDIA Container Toolkit**:
   ```bash
   # Add repository
   curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
     sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

   curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
     sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
     sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

   # Install
   sudo apt-get update
   sudo apt-get install -y nvidia-container-toolkit

   # Configure Docker
   sudo nvidia-ctk runtime configure --runtime=docker
   sudo systemctl restart docker

   # Verify
   docker run --rm --gpus all nvidia/cuda:12.0-base-ubuntu22.04 nvidia-smi
   ```

### Linux with AMD GPU

1. **Install ROCm kernel driver**:
   ```bash
   # Ubuntu 22.04
   wget https://repo.radeon.com/amdgpu-install/latest/ubuntu/jammy/amdgpu-install_6.0.60002-1_all.deb
   sudo apt install ./amdgpu-install_6.0.60002-1_all.deb
   sudo amdgpu-install --usecase=rocm

   # Add user to video and render groups
   sudo usermod -a -G video,render $USER

   # Verify
   rocm-smi
   ```

2. **Verify Docker access**:
   ```bash
   docker run --rm --device=/dev/kfd --device=/dev/dri \
     rocm/rocm-terminal:latest rocm-smi
   ```

### Windows with WSL2 + NVIDIA

1. **Install Windows NVIDIA Driver** (Game Ready or Studio):
   - Download from [NVIDIA website](https://www.nvidia.com/drivers)
   - **DO NOT** install Linux drivers inside WSL2

2. **Update WSL**:
   ```powershell
   wsl --update
   ```

3. **Install Docker Desktop** with WSL2 backend

4. **Verify**:
   ```bash
   # Inside WSL2
   docker run --rm --gpus all nvidia/cuda:12.0-base-ubuntu22.04 nvidia-smi
   ```

## Using dsHPC with GPU

### Setup

Simply run the setup script - GPU detection is automatic:

```bash
./configure-environment.sh
```

You'll see output like:
```
ðŸ” Detecting GPU configuration...
  Checking NVIDIA GPU...
  âœ“ NVIDIA GPU(s) detected: 1x NVIDIA GeForce RTX 3080
    Memory: 10240 MiB, Driver: 535.154.05
  Testing Docker NVIDIA GPU passthrough...
    âœ“ Docker GPU passthrough working
  âœ“ GPU is ready for Docker containers

âš™ï¸  Configuring Slurm with detected resources...
  Configuring Slurm for 1 nvidia GPU(s)
  Creating gres.conf for GPU resources...
  âœ“ gres.conf created
âœ“ Slurm configured with: 8 CPUs, 14374 MB RAM, 1 nvidia GPU(s)

âš™ï¸  Configuring Docker Compose with prefix: dshpc-imaging
  Adding GPU configuration to docker-compose.yml...
  âœ“ GPU configuration added to docker-compose.yml
```

### Running GPU Jobs

Once configured, jobs can request GPUs via Slurm GRES:

```bash
# Request 1 GPU
srun --gres=gpu:1 python my_gpu_script.py

# Request specific GPU type
srun --gres=gpu:nvidia:1 python my_gpu_script.py

# Batch job with GPU
sbatch --gres=gpu:1 my_job.sh
```

### Method Configuration

Methods can specify GPU requirements in their `method.json`:

```json
{
  "name": "deep-learning-method",
  "resources": {
    "min_memory_mb": 8192,
    "cpus": 4,
    "gpus": 1
  }
}
```

## Verification Commands

### Check GPU inside container

```bash
# NVIDIA
docker exec -it dshpc-imaging-slurm nvidia-smi

# AMD
docker exec -it dshpc-imaging-slurm rocm-smi
```

### Check Slurm GPU configuration

```bash
# View GRES resources
docker exec -it dshpc-imaging-slurm sinfo -o "%n %G"

# Should show: localhost gpu:nvidia:1 (or similar)

# View detailed node info
docker exec -it dshpc-imaging-slurm scontrol show node=localhost | grep Gres
```

### Test GPU job

```bash
# NVIDIA
docker exec -it dshpc-imaging-slurm srun --gres=gpu:1 nvidia-smi

# AMD
docker exec -it dshpc-imaging-slurm srun --gres=gpu:1 rocm-smi
```

## Troubleshooting

### "No GPU detected" during setup

**Cause**: GPU driver or container toolkit not installed/configured.

**Solution**:
1. Verify host can see GPU: `nvidia-smi` or `rocm-smi`
2. Verify Docker can access GPU (see Prerequisites above)
3. Re-run `./configure-environment.sh`

### "GPU detected but Docker passthrough failed"

**Cause**: nvidia-container-toolkit or AMD toolkit not configured.

**Solution for NVIDIA**:
```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

**Solution for AMD**:
```bash
# Ensure user is in video/render groups
sudo usermod -a -G video,render $USER
# Log out and back in
```

### GPU visible on host but not in container

**Cause**: docker-compose.yml missing GPU configuration.

**Solution**: Re-run setup or manually add to docker-compose.yml:

For NVIDIA:
```yaml
services:
  dshpc-imaging-slurm:
    # ... existing config ...
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

For AMD:
```yaml
services:
  dshpc-imaging-slurm:
    # ... existing config ...
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    security_opt:
      - seccomp:unconfined
    group_add:
      - video
      - render
```

### Slurm says "Invalid GRES specification"

**Cause**: Mismatch between slurm.conf and actual GPU.

**Solution**: Delete config files and restart:
```bash
rm config/slurm.conf config/gres.conf
docker-compose down
docker-compose up
```

The container will regenerate configuration based on actual detected hardware.

### Container built without GPU, now I have one

**Solution**: Rebuild with GPU support:
```bash
# Re-run setup to detect GPU
./configure-environment.sh

# Rebuild container with GPU support
docker-compose build --no-cache --build-arg GPU_TYPE=nvidia
docker-compose up
```

## Manual GPU Configuration

If automatic detection doesn't work for your setup, you can manually configure:

### 1. Edit docker-compose.yml

Add GPU section to the slurm service (see examples in Troubleshooting above).

### 2. Create config/gres.conf

```bash
# For NVIDIA
echo "AutoDetect=nvml" > config/gres.conf

# Or manual mapping
echo "NodeName=localhost Name=gpu Type=nvidia File=/dev/nvidia0" > config/gres.conf
```

### 3. Edit config/slurm.conf

Add before the NodeName line:
```
GresTypes=gpu
```

Modify NodeName line to include GRES:
```
NodeName=localhost CPUs=8 RealMemory=14374 Gres=gpu:nvidia:1 State=UNKNOWN
```

Mark as custom to prevent auto-regeneration:
```
# USER_CUSTOMIZED=true
```

### 4. Rebuild and restart

```bash
docker-compose build --no-cache --build-arg GPU_TYPE=nvidia
docker-compose up
```

## Why macOS Doesn't Support GPU

Docker on macOS runs containers inside a Linux VM (using Apple's Hypervisor framework). GPU passthrough requires:

1. **Hardware support**: VT-d/IOMMU for PCI passthrough
2. **Driver compatibility**: Linux GPU drivers in the VM
3. **Hypervisor support**: macOS Hypervisor doesn't expose GPU

Neither Intel Macs (with NVIDIA/AMD) nor Apple Silicon (with Metal) can pass GPUs to Docker containers.

**Alternatives for macOS users**:
- Use a remote Linux server with GPUs
- Use cloud GPU instances (AWS, GCP, Azure)
- Run GPU workloads natively with Metal/MPS (outside Docker)

## References

- [NVIDIA Container Toolkit Documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
- [Docker GPU Support](https://docs.docker.com/compose/how-tos/gpu-support/)
- [ROCm Docker Documentation](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/how-to/docker.html)
- [Slurm GRES Configuration](https://slurm.schedmd.com/gres.html)
- [CUDA on WSL](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)
